{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b2a45385",
   "metadata": {},
   "source": [
    "Quality concerns:\n",
    "Arkansas data from 2019 is corrupted.\n",
    "Mississippi data is from 2018.\n",
    "Alaska data is from 2016.\n",
    "No Puerto Rico data\n",
    "\n",
    "Big point: Appears to be no interstate commuting data, such as people coming from Kentucky into Ohio. \n",
    "--->>> this is in the aux files. Because of course it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8712551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "import simplejson as json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "from decimal import *\n",
    "from glob import glob\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaddir = \"downloads/\"\n",
    "rawdir = \"raw/\"\n",
    "parseddir = \"parsed/\"\n",
    "for mydir in [downloaddir, rawdir, parseddir]:\n",
    "    os.makedirs(mydir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67b9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "starturl = \"https://lehd.ces.census.gov/data/lodes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10710bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(starturl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da69be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lodesversion = pq(pq(r.content)(\"a\")[-1]).attr(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582ec842",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = starturl + lodesversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "131e82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd8f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {}\n",
    "for row in pq(r.content)(\"tr\"):\n",
    "    if pq(pq(row)(\"img\")).attr(\"src\") == \"/icons/folder.gif\":\n",
    "        state = pq(pq(row)(\"a\")[0]).attr(\"href\").replace(\"/\", \"\")\n",
    "        if state != \"us\":\n",
    "            states[state] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef9b9f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching ak\n",
      "Searching al\n",
      "Searching ar\n",
      "Searching az\n",
      "Searching ca\n",
      "Searching co\n",
      "Searching ct\n",
      "Searching dc\n",
      "Searching de\n",
      "Searching fl\n",
      "Searching ga\n",
      "Searching hi\n",
      "Searching ia\n",
      "Searching id\n",
      "Searching il\n",
      "Searching in\n",
      "Searching ks\n",
      "Searching ky\n",
      "Searching la\n",
      "Searching ma\n",
      "Searching md\n",
      "Searching me\n",
      "Searching mi\n",
      "Searching mn\n",
      "Searching mo\n",
      "Searching ms\n",
      "Searching mt\n",
      "Searching nc\n",
      "Searching nd\n",
      "Searching ne\n",
      "Searching nh\n",
      "Searching nj\n",
      "Searching nm\n",
      "Searching nv\n",
      "Searching ny\n",
      "Searching oh\n",
      "Searching ok\n",
      "Searching or\n",
      "Searching pa\n",
      "Searching pr\n",
      "Searching ri\n",
      "Searching sc\n",
      "Searching sd\n",
      "Searching tn\n",
      "Searching tx\n",
      "Searching ut\n",
      "Searching va\n",
      "Searching vt\n",
      "Searching wa\n",
      "Searching wi\n",
      "Searching wv\n",
      "Searching wy\n"
     ]
    }
   ],
   "source": [
    "badvalue = \"None found\"\n",
    "fileyears = {}\n",
    "for state in list(states.keys()):\n",
    "    print(f\"Searching {state}\")\n",
    "    stateurl = baseurl + state + \"/od/\"\n",
    "    r = requests.get(stateurl)\n",
    "    thingywanted = badvalue\n",
    "    for row in pq(r.content)(\"tr\")[2:]:\n",
    "        links = pq(row)(\"a\")\n",
    "        if links:\n",
    "            href = pq(pq(row)(\"a\")[0]).attr(\"href\")\n",
    "            if \"main_JT00\" in href:\n",
    "                thingywanted = href\n",
    "                # print(thingywanted)\n",
    "    if thingywanted == badvalue:\n",
    "        fileyear = badvalue\n",
    "    else:\n",
    "        fileyear = thingywanted.split(\"_\")[-1][:4]\n",
    "    if fileyear == \"2019\" and state == \"ar\":    # Patch for bad Arkansas 2019 data\n",
    "        fileyear = \"2018\"\n",
    "        thingywanted = thingywanted.replace(\"2019\", \"2018\")\n",
    "    if fileyear not in fileyears:\n",
    "        fileyears[fileyear] = []\n",
    "    fileyears[fileyear].append(state)\n",
    "    if thingywanted != badvalue:\n",
    "        targetfilename = downloaddir + state + fileyear + \".csv.gz\"\n",
    "        if not os.path.exists(targetfilename):\n",
    "            r = requests.get(stateurl + thingywanted)\n",
    "            with open(targetfilename, \"wb\") as outfile:\n",
    "                outfile.write(r.content)\n",
    "        \n",
    "        # Now get the aux files\n",
    "        thingywanted = thingywanted.replace(\"_main_\", \"_aux_\")\n",
    "        targetfilename = downloaddir + state + fileyear + \"_aux.csv.gz\"\n",
    "        if not os.path.exists(targetfilename):\n",
    "            r = requests.get(stateurl + thingywanted)\n",
    "            with open(targetfilename, \"wb\") as outfile:\n",
    "                outfile.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a99002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"2016\": [\n",
      "        \"ak\"\n",
      "    ],\n",
      "    \"2020\": [\n",
      "        \"al\",\n",
      "        \"az\",\n",
      "        \"ca\",\n",
      "        \"co\",\n",
      "        \"ct\",\n",
      "        \"dc\",\n",
      "        \"de\",\n",
      "        \"fl\",\n",
      "        \"ga\",\n",
      "        \"hi\",\n",
      "        \"ia\",\n",
      "        \"id\",\n",
      "        \"il\",\n",
      "        \"in\",\n",
      "        \"ks\",\n",
      "        \"ky\",\n",
      "        \"la\",\n",
      "        \"ma\",\n",
      "        \"md\",\n",
      "        \"me\",\n",
      "        \"mi\",\n",
      "        \"mn\",\n",
      "        \"mo\",\n",
      "        \"mt\",\n",
      "        \"nc\",\n",
      "        \"nd\",\n",
      "        \"ne\",\n",
      "        \"nh\",\n",
      "        \"nj\",\n",
      "        \"nm\",\n",
      "        \"nv\",\n",
      "        \"ny\",\n",
      "        \"oh\",\n",
      "        \"ok\",\n",
      "        \"or\",\n",
      "        \"pa\",\n",
      "        \"ri\",\n",
      "        \"sc\",\n",
      "        \"sd\",\n",
      "        \"tn\",\n",
      "        \"tx\",\n",
      "        \"ut\",\n",
      "        \"va\",\n",
      "        \"vt\",\n",
      "        \"wa\",\n",
      "        \"wi\",\n",
      "        \"wv\",\n",
      "        \"wy\"\n",
      "    ],\n",
      "    \"2018\": [\n",
      "        \"ar\",\n",
      "        \"ms\"\n",
      "    ],\n",
      "    \"None found\": [\n",
      "        \"pr\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(fileyears, indent=4*' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59721185",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataindex = {}\n",
    "downloadedfilesraw = sorted(list(glob(downloaddir + \"*.gz\")))\n",
    "\n",
    "# Filter out aux files, which should be paired with the mains\n",
    "downloadedfiles = []\n",
    "for downloadedfileraw in downloadedfilesraw:\n",
    "    if \"_aux\" not in downloadedfileraw:\n",
    "        downloadedfiles.append(downloadedfileraw)\n",
    "for downloadedfile in downloadedfiles:\n",
    "    base = downloadedfile.replace(\"\\\\\", \"/\").split(\"/\")[-1]    #base filename is everything in the ultimate directory\n",
    "    state = base[:2]\n",
    "    dataindex[state] = downloadedfile   # Update with the latest year of data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bae7c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:57<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use main and aux GZIPs to build a single CSV, badly.\n",
    "for state in tqdm(dataindex):\n",
    "    sourcefilename = dataindex[state]\n",
    "    targetfilename = rawdir + state + \".csv\"\n",
    "    with open(targetfilename, \"wb\") as outfile:\n",
    "        with gzip.open(sourcefilename, 'rb') as infile:\n",
    "            outfile.write(infile.read())\n",
    "        with gzip.open(sourcefilename.replace(\".csv\", \"_aux.csv\"), 'rb') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13ddcddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [12:54<00:00, 15.19s/it]\n"
     ]
    }
   ],
   "source": [
    "countyholder = {}\n",
    "csvfiles = sorted(list(glob(rawdir + \"*.csv\")))\n",
    "for csvfile in tqdm(csvfiles):\n",
    "    stateholder = {}\n",
    "    base = csvfile.replace(\"\\\\\", \"/\").split(\"/\")[-1][:2]\n",
    "    targetfilename = parseddir + base + \".json\"\n",
    "    with open(csvfile, \"r\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            if row['w_geocode'] != 'w_geocode':    # Skip extra header row from aux files\n",
    "                work = row['w_geocode'][:5]\n",
    "                home = row['h_geocode'][:5]\n",
    "                pop = int(row['S000'])\n",
    "                if work not in stateholder:\n",
    "                    stateholder[work] = {}\n",
    "                if home not in stateholder[work]:\n",
    "                    stateholder[work][home] = 0\n",
    "                stateholder[work][home] += pop\n",
    "\n",
    "    getcontext().prec = 6    # Decimal degrees of precision\n",
    "    betterstate = {}\n",
    "    betterstate['fileyear'] = \"\"\n",
    "    fileyear = \"error\"\n",
    "    for myyear in fileyears:\n",
    "        if base in fileyears[myyear]:\n",
    "            fileyear = myyear\n",
    "    betterstate['fileyear'] = fileyear\n",
    "    betterstate['commute'] = {}\n",
    "    betterstate['metadata'] = {}\n",
    "    for work in sorted(list(stateholder.keys())):\n",
    "        betterstate['commute'][work] = {}\n",
    "        betterstate['metadata'][work] = {}\n",
    "        betterstate['metadata'][work]['workers'] = 0\n",
    "        betterstate['metadata'][work]['counties'] = len(stateholder[work])\n",
    "        localwork = stateholder[work]\n",
    "        localwork = dict(sorted(stateholder[work].items(), key=lambda x: x[1], reverse=True))\n",
    "        for home in localwork:\n",
    "            betterstate['commute'][work][home] = {}\n",
    "            betterstate['commute'][work][home]['count'] = localwork[home]\n",
    "            betterstate['commute'][work][home]['share'] = 0\n",
    "            betterstate['metadata'][work]['workers'] += localwork[home]\n",
    "    for work in betterstate['commute']:\n",
    "        workvalue = Decimal(betterstate['metadata'][work]['workers'])\n",
    "        for home in betterstate['commute'][work]:\n",
    "            betterstate['commute'][work][home]['share'] = Decimal(betterstate['commute'][work][home]['count']) / workvalue\n",
    "    for work in betterstate['commute']:\n",
    "        countyholder[work] = betterstate['commute'][work]\n",
    "    with open(targetfilename, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(betterstate, indent=4*' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec7e08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedcounties = {}\n",
    "for work in sorted(list(countyholder.keys())):\n",
    "    sortedcounties[work] = countyholder[work]\n",
    "with open(\"us-county-commuters.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(sortedcounties, indent=4*' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c383e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
